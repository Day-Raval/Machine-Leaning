# -*- coding: utf-8 -*-
"""Train_Test Split.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f6YPUbARREpG3l0Lz-cnauX0gnE13fNQ

## Train-Test Split- Evaluating Model Fit:-
   
*  Underfitting
*  Overfitting
*  Perfect fit

## 1. Generate the data with the noise
"""

# Commented out IPython magic to ensure Python compatibility.
#some useful imports

import numpy as np
import numpy.random as rnd
import matplotlib.pyplot as plt
# %matplotlib inline
np.random.seed(42)
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

#Generate the dataset on whcih we will test various models

ndata=100
factor=100
X = 6*np.random.rand(ndata,1)-3
y = -0.5*X**2+X+2.5+np.random.randn(ndata,1)*factor

"""## 2. Generate features for a Model of Degree 1"""

#generate the polynomial features

degree=1
poly_features = PolynomialFeatures(degree=degree,include_bias=True)
X_poly = poly_features.fit_transform(X)

"""## 3. Do the train-test split using Random Sampling"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.20, random_state=42)

"""## 4. Build the model using the training set only"""

#train the model using training set
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

"""## 5. Find the error metrics on the training set"""

y_train_hat = lin_reg.predict(X_train)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_train,y_train_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_train,y_train_hat)))
print("R_squared:",metrics.r2_score(y_train,y_train_hat))

"""## 6. Find the error metrics on the testing set"""

y_test_hat = lin_reg.predict(X_test)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_test,y_test_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_test,y_test_hat)))
print("R_squared:",metrics.r2_score(y_test,y_test_hat))

"""# The above model is a case of Underfitting :-  
1. Error metrics are mediocre
2. This is repeating for both training and testing data



"""

# Generate the features , do the train/split, and train the model with training set and testing set

degree=20
poly_features = PolynomialFeatures(degree=degree,include_bias=True)
X_poly = poly_features.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.20, random_state=42)

#train the model using training set
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

y_train_hat = lin_reg.predict(X_train)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_train,y_train_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_train,y_train_hat)))
print("R_squared:",metrics.r2_score(y_train,y_train_hat))

y_test_hat = lin_reg.predict(X_test)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_test,y_test_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_test,y_test_hat)))
print("R_squared:",metrics.r2_score(y_test,y_test_hat))

"""# The above model is a case of Overfitting :-  
1. Error metrics are good for training set
2. All these metrics are exceptionally high for testing set



"""

# Generate the features , do the train/split, and train the model with training set and testing set

degree=2
poly_features = PolynomialFeatures(degree=degree,include_bias=True)
X_poly = poly_features.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.20, random_state=42)

#train the model using training set
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

y_train_hat = lin_reg.predict(X_train)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_train,y_train_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_train,y_train_hat)))
print("R_squared:",metrics.r2_score(y_train,y_train_hat))

y_test_hat = lin_reg.predict(X_test)

#Regression evaluation metrics
from sklearn import metrics

print("MAE:",metrics.mean_absolute_error(y_test,y_test_hat))
print("RMSE:",np.sqrt(metrics.mean_squared_error(y_test,y_test_hat)))
print("R_squared:",metrics.r2_score(y_test,y_test_hat))

"""# The above model is a case of Good fit :-  
1. Error metrics are fairly good for training set
2. All these metrics are comparable as well for testing set



"""